#!/bin/bash
##############################################################################
#
# pgarchive -- A PostgreSQL Archive Server
#
# See LICENSE for terms.
#
# Author: JÃ¼rgen Strobel <juergen.strobel@emarsys.com>
#
##############################################################################

### global env

# abort on all errors
set -e

# default PAGER
export PAGER=${PAGER:-less}

# clamp down locale, since we rely on date format and some other locale specifics
export LANG=en_US.UTF-8
export LC_ALL=en_US.UTF-8

# clear out incidential libpq settings
unset PGHOST PGHOSTADDR PGPORT PGDATABASE PGUSER PGPASSWORD PGPASSFILE
unset PGSERVICE PGSERVICEFILE PGREALM PGOPTIONS PGAPPNAME
unset PGSSLMODE PGREQUIRESSL PGSSLCOMPRESSION PGSSLCERT PGSSLKEY PGSSLROOTCERT
unset PGSSLCRL PGREQUIREPEER PGKRBSRVNAME PGGSSLIB PGCONNECT_TIMEOUT PGCLIENTENCODING
unset PGDATA


### global config, eventually to be moved out to /etc/pgarchive.conf (very incomplete)

# For the following configuration snippets these placeholders will be replaced
# intelligently and if applicable:
#
# __PGARCHIVE__     full path to self
# __SLOT__          name of replication slot used
# __PORT__          port to use for a clone
# __TARGET__        whole clone target-selecting recovery.conf option
# __CLONE__         clone name

# added to postgresql.conf for the standby process
standby_postgresql_conf_9_4="\
listen_addresses = ''
port = 5432
unix_socket_directories = 'socket'
max_connections = 10
shared_buffers = 1024MB
checkpoint_segments = 16
wal_keep_segments = 0
synchronous_standby_names = ''
hot_standby = off
"

standby_postgresql_conf_9_5="\
cluster_name = '__SLOT__'
listen_addresses = ''
port = 5432
unix_socket_directories = 'socket'
max_connections = 10
shared_buffers = 1024MB
max_wal_size = 1GB
min_wal_size = 80MB
wal_keep_segments = 0
synchronous_standby_names = ''
hot_standby = off
wal_retrieve_retry_interval = 60s
"

# template for standby's recovery.conf
standby_recovery_conf="\
standby_mode = 'on'
restore_command = '__PGARCHIVE__ standby-restore %f %p'
archive_cleanup_command = '__PGARCHIVE__ standby-record-cleanup-position %r'
recovery_target_timeline = 'latest'
"

# added to postgresql.conf for clones
clone_postgresql_conf_9_4="\
listen_addresses = ''
port = __PORT__
shared_buffers = 2GB
checkpoint_segments = 16
synchronous_standby_names = ''
wal_keep_segments = 0
#autovacuum = off
#fsync = off
#synchronous_commit = off
"

clone_postgresql_conf_9_5="\
cluster_name = '__CLONE__'
listen_addresses = ''
port = __PORT__
shared_buffers = 2GB
max_wal_size = 1GB
min_wal_size = 80MB
synchronous_standby_names = ''
wal_keep_segments = 0
#autovacuum = off
#fsync = off
#synchronous_commit = off
"

clone_recovery_conf_9_4="\
standby_mode = 'off'
restore_command = '__PGARCHIVE__ clone-restore %f %p'

__TARGET__

# alternative recovery targets
#recovery_target = 'immediate'
#recovery_target_time = 'TIME'
#recovery_target_name = 'NAME'
#recovery_target_xid = 'X'

#recovery_target_inclusive = 'true'

# If true, commit with 'select pg_xlog_replay_resume()' or kill to abort.
# See http://www.postgresql.org/docs/9.4/static/recovery-target-settings.html.
pause_at_recovery_target = false
"

clone_recovery_conf_9_5="\
standby_mode = 'off'
restore_command = '__PGARCHIVE__ clone-restore %f %p'

__TARGET__

# alternative recovery targets
#recovery_target = 'immediate'
#recovery_target_time = 'TIME'
#recovery_target_name = 'NAME'
#recovery_target_xid = 'X'

#recovery_target_inclusive = 'true'

# Select one of pause, promote, shutdown.
# When using pause, commit with 'select pg_xlog_replay_resume()' or kill to abort.
# See http://www.postgresql.org/docs/9.5/static/recovery-target-settings.html.
recovery_target_action = promote
"

# default filesystem volume management functions using btrfs

# Create a new and empty subvolume at path $1. This path must not exist yet, but it's parent does.
fs_create_subvolume() {
    btrfs subvolume create "$1"
}

# Create a new read only snapshot of $1 at $2. Try to set read-only if $3 is non empty.
# $1 must exist and must have been created by fs_create_subvolume or fs_create_snapshot.
fs_create_snapshot() {
    [[ -n "$3" ]] && ro="-r" || ro=""
    btrfs subvolume snapshot $ro "$1" "$2"
}

# Delete an existing subvolume (including snapshots) at path $1.
fs_delete_subvolume() {
    # some versions of btrfs insist ro subvols may not be deleted
    btrfs property set -t subvol "$1" ro false
    btrfs subvolume delete --commit-after "$1"
}

# Called in large intervals by cron, may do defragmentation or other tasks.
# This version requires sudo privileges, because defragmentation may be done by root only.
# This function is passed $PGARCHIVE as parameter.
fs_maintenance() {
    local btrfsprog=$(which btrfs)
    log sudo -n "$btrfsprog" filesystem defrag -t1M -f -r "$1/standby"
    time sudo -n "$btrfsprog" filesystem defrag -t1M -f -r "$1/standby"
}

### internal utils

datefmt='%Y-%m-%dT%R:%SZ'
pg_ctl_timeout=3600

log() {
  echo `date +"$datefmt" --utc` "$*"
}

fail() {
    log "ERROR $*"
    exit 1
}

debug() {
    [[ -n "$DEBUG" ]] && log "DEBUG $*" || true
}

configure() {
    set_container
    [[ -d "$container" ]] || fail "$PGARCHIVE does not exist."

    setup
    . $config
    export PATH="$path"

    retired=""
    [[ ! -f "$container/_RETIRED_" ]] || retired="y"
}

set_container() {
    [[ -n "$PGARCHIVE" ]] || fail "\$PGARCHIVE is not defined, please read 'help'."
    container=`readlink -f $PGARCHIVE`
}

setup() {
    config="$container/pgarchive.conf"
    log="$container/log"
    standby="$container/standby"
    standby_saved_conf="$log/standby_saved_conf"
    wal="$container/wal_archive"
    wal="$container/wal_archive"
    snapshots="$container/snapshots"
    clones="$container/clones"

    wallog="$log/wal_archive.log"
    walpid="$log/wal_archive.pid"
    slot=${SLOT:-pgarchive_$(basename "$container")}
    standby_cleanup_position="$standby/pgarchive_cleanup_position"
    standbylog="$log/standby/postgresql-$(date +'%a').csv"
    cron_snapshotlog="$log/cron_snapshot.log"
    cron_wallog="$log/cron_wal_archive.log"
    cron_maintenancelog="$log/cron_maintenance.log"
}

check_retired() {
    [[ -n "$retired" ]] || fail "Operation only possible for a retired container."
}

check_not_retired() {
    [[ -z "$retired" ]] || fail "Operation not possible for a retired container."
}

psql_upstream() {
    local cmd=$1
    shift
    psql -d "$upstream" -c "$cmd" $@
}

get_upstream_version() {
    psql -qtA -d "$upstream" -c \
       "select string_agg(n, '.') from (select unnest(regexp_matches(version(), E'PostgreSQL "'(\\d+)\\.(\\d+)'"'))) v(n)"
}

create_slot() {
    log "Creating replication slot $slot in upstream DB cluster."
    psql_upstream "select pg_create_physical_replication_slot('$slot');" >/dev/null
}

drop_slot() {
    log "Dropping replication slot $slot in upstream DB cluster."
    psql_upstream "select pg_drop_replication_slot('$slot');" >/dev/null
}

pg_ctl_cmd() {
    local pgd=$1
    local cmd=$2
    shift 2
    pg_ctl -D "$pgd" "$cmd" -t $pg_ctl_timeout $@
}

pg_ctl_status() {
    pg_ctl_cmd $1 status >/dev/null 2>&1
}

new_clone_port() {
    local lastport=$(cat $log/last_clone_port 2>/dev/null) || lastport=$((54000 + $RANDOM % 700))
    local newport=$(($lastport + 1))
    echo $newport > "$log/last_clone_port"
    echo $newport
}

show_log() {
    [[ "$1" = "-f" ]] && tail -f "$2" || "$PAGER" "$2"
}

do_or_show() {
    $@
}
enable_dry_run() {
    dry_run="1"
    do_or_show() {
        echo "not executed: $@"
    }
}

versioned_var() {
    local prefix="$1"
    local varname="${prefix}_${upstream_version//./_}"
    local value="${!varname}"
    if [[ -n "$value" ]]; then
        echo "$value"
    else
        value="${!prefix}"
        if [[ -n "$value" ]]; then
            echo "$value"
        else
            fail "Neither $varname nor $prefix is defined."
        fi
    fi
}

versioned_conf() {
    local self="$(which $0)"
    local tmpl=$(versioned_var "$1")
    local header="$2"
    local footer="$3"
    local port="$4"
    local target="$5"
    local clone="$6"
    tmpl=${tmpl//__PGARCHIVE__/$self}
    tmpl=${tmpl//__SLOT__/$slot}
    tmpl=${tmpl//__PORT__/$port}
    tmpl=${tmpl//__TARGET__/$target}
    tmpl=${tmpl//__CLONE__/$clone}
    echo "${header}${tmpl}${footer}"
}

### internal commands
#
# Used internally as restore_command or similiar in generated postgresql.conf files.
# They are executed without the usual setup() ceremony, by postgres, with cwd=$PGDATA.
# All restore_command scripts can handle plain and gzipped files.

standby_restore() {

    wal="../wal_archive"
    src="$wal/$1"
    zsrc="${src}.gz"
    dst="$2"

    [[ -d "$wal" ]] || fail "The wal_archive directory does not exist, something is very wrong."

    cp --reflink=always "$src" "$dst" 2>/dev/null || zcat "$zsrc" > "$dst" 2>/dev/null
}

# The pgarchive_cleanup_position file is used by wal_archive compression,
# snapshotting, and expiry to select appropriate WAL segments.
standby_record_cleanup_position() {

    cleanup_position="pgarchive_cleanup_position"
    restartpoint="$1"

    # Note: This rm works around a quirk in our monitoring setup.
    # Forced rm of $cleanup_position updates the standby directory's mtime,
    # which is later frozen as snapshot and used by activity monitoring.
    # It would be both simpler and better to monitor snapshot/.'s mtime directly.
    rm -f "$cleanup_position"
    echo "$restartpoint" > "$cleanup_position"
}

clone_restore() {

    wal="../../wal_archive"
    src="$wal/$1"
    zsrc="$wal/${1}.gz"
    dst="$2"

    [[ -d "$wal" ]] || fail "The wal_archive directory does not exist, something is very wrong."

    cp --reflink=auto "$src" "$dst" 2>/dev/null || zcat "$zsrc" > "$dst" 2>/dev/null
}


### user commands
#
# Many simple user commands are handled inline in the main switch.

help() {
    cat <<EOF
PGARCHIVE=<dir> `basename $0` <cmd> <arg...>

Commands and sub-commands:

help                Show this help.

container init      Create a new container and upstream replication slot, both of which
                    must not exist yet. This requires additional environment variables to be set,
                    see below. The new backup container is fully started and operational at the end,
                    except you need to verify and enable the cron jobs (crontab -e).
container purge [--force]
                    Completely remove the full backup location and the replication slot.
                    Tries to read PGARCHIVE's config, and falls back to the same
                    extra environment parameters init uses. Make sure nothing at all is needed
                    any more, and everything is stopped.
container start     Start backup container, which starts both wal_archive and standby processes.
container stop      Stop backup container.
container status    Show status of wal_archive and standby subsystems, exit 1 if any is not running.
container dashboard Show detailed status and tails of all log files.
container retire [--force]
                    Disconnect from upstream DB, but keep data for restores.
                    Releases the replication slot, and completely removes the standby subvolume.
                    With --force errors are ignored, useful e.g. if the slot is gone already.
container resync    Re-connect a retired container by creating a connection slot and doing a fresh
                    pg_basebackup. The old standby configuration is preserved.
container initcron  Add default cron entries to the calling user's crontab, all jobs disabled.
container checkversions
                    Check versions of upstream DB and local PostgreSQL tools.
container upstream  Open a psql shell to upstream database, additional arguments are passed through.

wal_archive start   Start the wal_archive process. This process connects to the upstream DB
                    using the PostgreSQL's replication protocol, with the configured
                    replication slot, and stores retrieved WAL segments in the wal_archive
                    directory. Implemented by using pg_receivexlog.
wal_archive stop    Stop the wal_archive process.
wal_archive status  Check if the wal_archive process is running.
wal_archive list    List wal_archive directory and size.
wal_archive du      Show disk usage per day and total (by segment mtime).
wal_archive log [-f]
                    Write wal_archive.log to stdout or tail -f it.
                    If stdout is a terminal \$PAGER is used to show it.

standby (start|stop|status|reload|restart) [arg] ...
                    The standby process is a warm standby PostgreSQL instance which pulls
                    completed segments from the wal_archive directory. This is a simple frontend
                    to control it using pg_ctl, and extra arguments are passed through.
standby log [-f]    Write today's standby log to stdout or tail -f it.
                    If stdout is a terminal \$PAGER is used to show it.
                    Assumes the standard weekly log rotation and CSV logging in standby/pg_log.

snapshot create [--force]
                    Create a new btrfs snapshot of the standby directory under snapshots/.
                    With --force do this even when the standby process is not running,
                    and or if there's no recent restartpoint.
snapshot delete <pattern> ...
                    Directly delete one or more snapshots, may use a simple globbing pattern.
snapshot expire [--show]
                    Delete snapshots older than \$expire_date, which should be defined in the
                    config file. Passing \$EXPIRE_DATE in the environment may be used to
                    override the config file. This also removes WAL segments which are not
                    needed any more from the wal_archive.
                    The format of the date must be understood by date (1) --date=STRING,
                    and may be a relative term like "1 week ago".
                    With --show only show the actions to be taken, but don't delete anything.
snapshot thin [--show]
                    Delete snapshots older than \$thin_daily_date which are not the first snapshot
                    of a day. This allows to thin snapshot density for older data. Like expire
                    this supports --show and overriding the config file with \$THIN_DAILY_DATE.
snapshot list [<pattern>]
                    List snapshots, optionally restricted to a simple globbing pattern.

clone create <name> <snapshot> [<target-time>]
                    Create a new named (PostgreSQL) clone instance from a snapshot.
                    A new port is assigned and appended to postgresql.conf.
                    The clone will have a recovery.conf suitable to do recovery to
                    either the next consistent point in time, or an arbitrary target time
                    (which should be after snapshot creation time). The clone is not
                    started automatically, so you may edit *.conf files before
                    initiating recovery. Recovery success depends on the wal_archive
                    still containing all required WAL segments.
clone duplicate <source> <target>
                    Duplicates an existing clone instance. Note that if source is running
                    target will have to do crash recovery once started. A new port is
                    assigned and appended to postgresql.conf automatically.
clone delete <name> Delete a (stopped) clone.
clone (start|stop|status|reload|restart) <name> [arg] ...
                    This is a simple frontend for pg_ctl to start and stop named clones.
                    The stop command also accepts --all instead of <name>.
clone list [--status] [<pattern>]
                    List clones, optionally restricted to a simple globbing pattern.
                    With --status the assigned port and pg_ctl status is given for each.
clone log <name> [-f]
                    Write the named clone's log to stdout or tail -f it.
                    If stdout is a terminal \$PAGER is used to show it.
                    Assumes the standard weekly log rotation and csv logging.
clone psql <name> [arg] ...
                    Open a psql shell connected to a running named clone instance.
                    Additional arguments are passed through.

cron compress-wal-archive
                    Compress completed segments in wal_archive, which have already been
                    processed by the standby process. Logs to log/cron_wal_archive.log.
cron expire-and-create-snapshot
                    Expire old snapshots and wal segments, thin snapshots, and create a new one.
                    The log is written to log/cron_snapshot.log.
cron maintenance    Defragment the standby directory, since PostgreSQL tends to cause a critical
                    amount of btrfs fragmentation fast. Requires password-less sudo privileges to
                    call "/sbin/btrfs filesystem defrag ...". Logs to log/cron_maintenance.log.

bash-completion     Output a bash completion snippet for this utility.
                    This may be saved to global or personal profiles, or eval'ed directly:
                        eval "\$(pgarchive bash-completion)"

Environment:

PGARCHIVE           Required base path to a backup container, which must be on btrfs.
PGARCHIVE_CONF      Optional path to a global config file.

        The following environment parameters are only used by the 'container init' and 'purge'
        commands, and written to the \$PGARCHIVE/pgarchive.conf container config file on 'init'.

PATH                The PATH used internally. This must contain PostgreSQL's server applications
                    (pg_ctl, pg_basebackup, ...) of the same version as the DB cluster a container
                    is created for.
SLOT                Create and use this replication slot at upstream. Defaults to
                    "pgarchive_<basename of \$PGARCHIVE>".
UPSTREAM            A connection info string used when accessing the upstream DB in
                    command mode, for example when creating a SLOT or checking status. See
                    http://www.postgresql.org/docs/9.4/static/libpq-connect.html#LIBPQ-CONNSTRING.
                    The default value is "" (local connection, default port, user, DB etc.)
                    This is persisted to the config file and may be edited there later.
                    Note that common libpq environment settings (PG*) which are active in the
                    caller's shell are explicitly cleared by pgarchive. This must work without
                    a password prompt, and the DB user must have sufficient privileges to
                    create a connection slot.
UPSTREAM_REPL       The connection info string the WAL archive process uses to fetch
                    new WAL segments. Defaults to UPSTREAM + " user=replication".
                    All of UPSTREAM's caveats apply.

Configuration files:

\$PGARCHIVE_CONF     If defined this is sourced as shell script after all internal variables and
                    functions have been defined, but before commands are executed. This could be
                    used to override internal variables and functions, at your own risk.
/etc/pgarchive.conf This is only read if \$PGARCHIVE_CONF is not defined, in the same fashion
                    as \$PGARCHIVE_CONF.
\$PGARCHIVE/pgarchive.conf
                    This per-container config file is always read after the global one.
                    It contains container specific settings, like DB connection settings,
                    the PATH to use, and some settings regarding expiry and cron jobs.

EOF
}

bash_completion() {
    cat <<'EOF'
# pgarchive autocompletion for bash
_pgarchive() {
    local cur cmd subcmd cmds context
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    cmd=""
    subcmd=""
    [[ $COMP_CWORD -ge 2 ]] && cmd="${COMP_WORDS[1]}"
    [[ $COMP_CWORD -ge 3 ]] && subcmd="${COMP_WORDS[2]}"

    declare -A cmds
    cmds["/"]="help container wal_archive standby snapshot clone cron"
    cmds["container/"]="start stop status dashboard init purge initcron checkversions upstream retire resync"
    cmds["wal_archive/"]="start stop status list du log"
    cmds["standby/"]="start stop status restart reload log"
    cmds["snapshot/"]="create delete expire thin list"
    cmds["snapshot/create"]="--force --no-force"
    cmds["snapshot/delete"]="SNAPSHOT"
    cmds["snapshot/expire"]="--show"
    cmds["snapshot/thin"]="--show"
    cmds["clone/"]="list create restore duplicate start stop status reload restart delete log psql"
    cmds["clone/list"]="--status"
    cmds["clone/create"]="CREATE_CLONE"
    cmds["clone/duplicate"]="CLONE"
    cmds["clone/start"]="CLONE"
    cmds["clone/stop"]="CLONE_OR_ALL"
    cmds["clone/status"]="CLONE"
    cmds["clone/reload"]="CLONE"
    cmds["clone/restart"]="CLONE"
    cmds["clone/delete"]="CLONE"
    cmds["clone/log"]="CLONE"
    cmds["clone/psql"]="CLONE"
    cmds["cron/"]="compress-wal-archive expire-and-create-snapshot maintenance"

    context=${cmds["${cmd}"/"${subcmd}"]} || return 1
    case "$context" in
        SNAPSHOT)
            COMPREPLY=($(compgen -W "`ls $PGARCHIVE/snapshots`" -- ${cur}))
            ;;
        CLONE)
            COMPREPLY=($(compgen -W "`ls $PGARCHIVE/clones`" -- ${cur}))
            ;;
        CLONE_OR_ALL)
            COMPREPLY=($(compgen -W "`ls $PGARCHIVE/clones` --all" -- ${cur}))
            ;;
        CREATE_CLONE)
            case $COMP_CWORD in
                4)
                    COMPREPLY=($(compgen -W "`ls $PGARCHIVE/snapshots`" -- ${cur}))
                    ;;
                *)
                    COMPREPLY=()
                    ;;
            esac
            ;;
        *)
            COMPREPLY=($(compgen -W "${context}" -- ${cur}))
            ;;
    esac
    return 0
}
complete -F _pgarchive pgarchive
EOF
}

container_init() {

    upstream=${UPSTREAM:-""}
    upstream_repl=${UPSTREAM_REPL:-"$upstream"}

    get_and_check_upstream_version
    check_pg_apps $upstream_version

    log "."
    log "Setting up backup location $container."
    fs_create_subvolume "$container"
    fs_create_subvolume "$wal"
    fs_create_subvolume "$standby"
    mkdir "$log" "$snapshots" "$clones"
    chmod 700 "$container" "$standby"
    create_own_conf

    log "."
    log "Creating warm standby."
    # Note: pg_basebackup sometimes exits non zero on mere warnings
    # (e.g. "could not send feedback packet"). For this reason let's not be picky here,
    # if something worse happened we'll find out soon enough.
    PGAPPNAME="${slot}_basebackup" \
        pg_basebackup -D "$standby" --xlog-method=stream --progress --verbose --no-password \
        --label "$slot base backup" -d "$upstream_repl" || true
    rm -f "$standby/pg_log"/* "$standby/recovery.*"
    mkdir "$standby/socket"
    mv "$standby/pg_log" "$log/standby"
    ln -s ../log/standby "$standby/pg_log"
    mv "$standby/pg_xlog" "$log/standby_xlog"
    ln -s ../log/standby_xlog "$standby/pg_xlog"
    create_standby_conf

    log "."
    log "Creating WAL archive at $wal."
    create_slot
    seed_wal_archive
    $0 wal_archive start
    sleep 1

    log "."
    log "Creating first snapshot."
    snapshot_create

    log "."
    sleep 2
    $0 standby start
    sleep 5
    # Doing this earlier may cause clog problems:
    # http://www.postgresql.org/message-id/20150621213916.GD4797@alap3.anarazel.de
    rm -f "$standby/backup_label"*

    log "."
    init_cron
}

create_own_conf() {

    cat >"$config" <<EOF

# pgarchive container configuration

# upstream DB parameters
slot='$slot'
upstream='$upstream'
upstream_repl='$upstream_repl'
upstream_version='$upstream_version'

# path to all used applications, must contain PostgreSQL server applications of the same
# version as the upstream database, btrfs, and commonly used shell utilities
path='$PATH'

# number of CPUs to use in the cron job "compress-wal-archive"
compress_threads=1

# snapshots are only created if the standby process has a restartpoint less than this minutes ago
snapshot_max_restartpoint_minutes=65

# snapshots and associated WAL segments are expired after this time (date (1) relative format)
expire_date='4 weeks ago'

# snapshots are thinned to 1 per day after this time
thin_daily_date='2 weeks ago'

# all pg_ctl invocations are passed a --timeout parameter with this value
pg_ctl_timeout=3600
EOF
}

create_standby_conf() {

    header="
# recovery.conf for pgarchive's standby subsystem

"
    versioned_conf "standby_recovery_conf" "$header" >"$standby/recovery.conf"

    header="
# @@@standby-config-start@@@
# overrides for standby instance which is the source of the snapshots archive
"
    footer="
# @@@standby-config-end@@@

"
    versioned_conf "standby_postgresql_conf" "$header" "$footer" >>"$standby/postgresql.conf"
}

seed_wal_archive() {
    cp --reflink=always "$log/standby_xlog"/???????????????????????? "$wal"
    last=$(ls "$wal" | egrep '^.{24}$' | tail -n 1)
    mv "$wal/$last" "$wal/$last.partial"
}

init_cron() {

    log "Adding commented out cron jobs, you need to check and enable them using 'crontab -e'."
    self="$(which $0)"
    # "crontab -l" can fail if there is no crontab
    ( crontab -l 2>/dev/null || true && cat <<EOF ) | crontab -

# *** pgarchive container $container ***
#*/5 * * * *            PGARCHIVE='$container' '$self' cron compress-wal-archive
#01 */4 * * *           PGARCHIVE='$container' '$self' cron expire-and-create-snapshot
#05 01 * * sun          PGARCHIVE='$container' '$self' cron maintenance

EOF
}

get_and_check_upstream_version() {

    upstream_version=$(get_upstream_version)
    log "Detected upstream is PostgreSQL version $upstream_version."
    case $upstream_version in
        9.4|9.5)
            ;;
        *)
            fail "upstream version $upstream_version is not supported"
            ;;
    esac
}

check_pg_apps() {
    expected=$1
    for app in pg_ctl pg_receivexlog pg_basebackup pg_archivecleanup pg_controldata ; do
        $app --version | grep "$expected" > /dev/null || \
            fail "$app is for a wrong version, correct your \$PATH and/or install the correct version"
    done
    log "Verified PostgreSQL server applications' versions."
}

container_purge() {

    # continue over errors here
    set +e

    # if no $slot from config file fallback to $SLOT from environment
    slot=${slot:-$SLOT}
    drop_slot

    log "Deleting btrfs volumes."
    for subvol in "$wal" "$standby" "$snapshots"/* "$clones"/* "$container"; do
        fs_delete_subvolume "$subvol"
    done

    log "Please clean up the crontab yourself (crontab -e)."
}

container_retire() {

    log "Retiring container."
    ! $0 wal_archive status >/dev/null || $0 wal_archive stop
    ! $0 standby status >/dev/null || $0 standby stop

    drop_slot
    mkdir -p "$standby_saved_conf"
    cp "$standby"/*.conf "$standby_saved_conf"
    fs_delete_subvolume "$standby"
    rm -rf "$log/standby_xlog"

    touch "$container/_RETIRED_"
}

container_resync() {

    log "Resyncing container."

    log "."
    log "Creating new standby."
    fs_create_subvolume "$standby"
    chmod 700 "$standby"
    PGAPPNAME="${slot}_basebackup" \
        pg_basebackup -D "$standby" --xlog-method=stream --progress --verbose --no-password \
        --label "$slot base backup" -d "$upstream_repl" || true

    mkdir "$standby/socket"
    rm -f "$standby/recovery.*"
    rm -rf "$standby/pg_log"
    ln -s ../log/standby "$standby/pg_log"
    rm -rf "$log/standby_xlog"
    mv "$standby/pg_xlog" "$log/standby_xlog"
    ln -s ../log/standby_xlog "$standby/pg_xlog"
    cp "$standby_saved_conf"/* "$standby"
    rm -rf "$standby_saved_conf"
    rm "$container/_RETIRED_"

    log "."
    log "Resyncing wal_archive."
    create_slot
    seed_wal_archive
    $0 wal_archive start
    sleep 1

    log "."
    log "Creating a snapshot."
    snapshot_create

    $0 standby start
    sleep 5
    rm -f "$standby/backup_label"*
}


snapshot_check_cleanup_position() {
    at_most_minutes_ago="-$1"
    [[ -n $(find $standby_cleanup_position -cmin $at_most_minutes_ago 2>/dev/null) ]] &&
        seg=$(cat "$standby_cleanup_position" 2>/dev/null) &&
        [[ -f "$wal/$seg" || -f "$wal/$seg.gz" ]]
}

snapshot_date() {
    echo $(date +"$datefmt" --utc \
        --date="$(pg_controldata $standby | grep "latest checkpoint" | cut -d: -f2-)")
}

snapshot_create() {

    [[ -n "$1" ]] && date="$1" || date=$(snapshot_date)
    log "Creating snapshot $date."
    fs_create_snapshot "$standby" "$snapshots/$date" "ro"
}

snapshot_expire() {

    cutoff=$(date +"$datefmt" --utc --date="$expire_date")
    maxwalcutoff="000000000000000000000000"
    log "Expiring snapshots before $cutoff."
    for s in $(cd "$snapshots" && ls -1); do
        if [[ "$s" < "$cutoff" ]]; then
            if [[ -f "$snapshots/$s/pgarchive_cleanup_position" ]]; then
                walcutoff=$(<"$snapshots/$s/pgarchive_cleanup_position")
                [[ "$walcutoff" > "$maxwalcutoff" ]] && maxwalcutoff="$walcutoff"
            fi
            do_or_show fs_delete_subvolume "$snapshots/$s"
        fi
    done
    if [[ "$maxwalcutoff" = "000000000000000000000000" ]]; then
        log "No WAL segments to expire."
    else
        if [[ -n "$dry_run" ]]; then
            log "Expiring related WAL segments before $maxwalcutoff (DRY RUN)."
            pg_archivecleanup -n -x .gz "$wal" "$maxwalcutoff"
            pg_archivecleanup -n -x .partial "$wal" "$maxwalcutoff"
        else
            log "Expiring related WAL segments before $maxwalcutoff."
            pg_archivecleanup -x .gz "$wal" "$maxwalcutoff"
            pg_archivecleanup -x .partial "$wal" "$maxwalcutoff"
        fi
    fi
}

snapshot_thin_daily() {

    cutoff=$(date +"$datefmt" --utc --date="$thin_daily_date")
    log "Thinning snapshots to 1/day before $cutoff."
    curday=""
    for s in $(cd "$snapshots" && ls -1); do
        if [[ "$s" < "$cutoff" ]]; then
            day=${s:0:10}
            if [[ "$curday" = "$day" ]]; then
                do_or_show fs_delete_subvolume "$snapshots/$s"
            else
                curday=$day
                debug "keeping $s as first of day"
            fi
        fi
    done

}

clone_create() {

    [[ -z "$1" ]] && fail "clone name required"
    clone="$clones/$1"
    [[ -e "$clone" ]] && fail "$clone already exists"

    src="$snapshots/$2"
    [[ -d "$src" ]] || fail "$src does not exist"

    fs_create_snapshot "$src" "$clone"
    log "created from $src" > "$clone/pgarchive.log"

    rm -rf "$clone/pg_log" "$clone/pg_xlog" "$clone/socket" "$clone"/postmaster.*
    mkdir "$clone/pg_log" "$clone/pg_xlog"

    header="
# recovery.conf for activating a clone of a snapshot

"
    port=$(new_clone_port)
    [[ -n "$3" ]] \
        && target="recovery_target_time = '$3'" \
        || target="recovery_target = 'immediate'"
    versioned_conf "clone_recovery_conf" "$header" "" "$port" "$target" "$1" \
        >"$clone/recovery.conf"

    header="
# @@@clone-config-start@@@
# default overrides for a clone, feel free to change them as needed
"
    footer="
# @@@clone-config-end@@@

"
    sed -i".snapshot" '/@@@standby-config-start@@@/,/@@standby-config-end@@@/d' "$clone/postgresql.conf"
    versioned_conf "clone_postgresql_conf" "$header" "$footer" "$port" "$target" "$1" \
        >>"$clone/postgresql.conf"

    log "Created new clone, recovery will be initiated once started."
    log "You may edit postgresql.conf and recovery.conf if custom options are desired."
}

clone_duplicate() {

    dup="$clones/$1"
    [[ -n "$1" ]] || fail "new clone name required"
    [[ -e "$dup" ]] && fail "clone $1 already exists"

    fs_create_snapshot "$clone" "$dup"
    rm -f "$dup"/postmaster.*
    log "duplicated from clone $(basename $clone)" >> "$dup/pgarchive.log"

    echo "# override port for duplicate" >>"$clone/postgresql.conf"
    echo "port = $(new_clone_port)" >>"$clone/postgresql.conf"
    echo "" >>"$clone/postgresql.conf"
}


### main

# Read extra global config, which may change any of the above variables and functions.
if [[ -n "$PGARCHIVE_CONF" ]]; then
    . "$PGARCHIVE_CONF"
elif [[ -f /etc/pgarchive.conf ]]; then
    . /etc/pgarchive.conf
fi

# command switch
cmd=$1
shift || true
case "$cmd" in

    # internal

    standby-restore)
        standby_restore $@
        ;;

    standby-record-cleanup-position)
        standby_record_cleanup_position $@
        ;;

    clone-restore)
        clone_restore $@
        ;;

    # user commands

    help|--help)
        help
        ;;

    bash-completion)
        bash_completion
        ;;

    container)
        subcmd=$1
        shift || true

        case "$subcmd" in
            init)
                # no configure here, as we don't have anything yet
                set_container
                setup
                container_init
                ;;

            purge)
                # no configure here either, configuration may be present or not
                set_container
                setup
                [[ -f $config ]] && . $config

                $0 wal_archive status >/dev/null 2>&1 && fail "wal_archive must be stopped"
                $0 standby status >/dev/null 2>&1 && fail "standby must be stopped"
                ($0 clone list --status | grep "server is running") >/dev/null 2>&1 && fail "all clones must be stopped"

                if [[ "$1" = '--force' ]]; then
                    log "Completely purging $container."
                    log "Any errors are ignored and left to manual cleanup, or you may repeat this."
                    container_purge
                else
                    log "If you really want to purge $container and remove upstream's $slot slot, provide --force."
                    log "WARNING: this will delete EVERTHING under $container."
                fi
                ;;

            *)
                configure
                ;;&

            initcron)
                init_cron
                ;;

            status)
                if [[ -n "$retired" ]]; then
                    echo "Container is retired."
                else
                    status1=0
                    status2=0
                    $0 wal_archive status || status1=1
                    $0 standby status || status2=2
                    exit $((status1 + status2))
                fi
                ;;

            dashboard)
                status1=0
                status2=0
                if [[ -n "$retired" ]]; then
                    echo "Container is retired."
                else
                    $0 wal_archive status || status1=1
                    $0 standby status || status2=2
                fi

                set +e

                echo ""
                df -hP "$container"

                if [[ $status1 = 0 || $status2 = 0 ]]; then
                    echo ""
                    echo "Processes:"
                    [[ $status1 = 0 ]] && wal_pid=$(head -n1 "$log/wal_archive.pid" 2>/dev/null) || wal_pid=1234567890
                    [[ $status2 = 0 ]] && standby_pid=$(head -n1 "$standby/postmaster.pid" 2>/dev/null) || standby_pid=1234567890
                    ps --pid $wal_pid --pid $standby_pid --ppid $standby_pid f
                fi

                echo ""
                echo "Replication status:"
                pr -m -t -w 102 \
                    <(psql_upstream "select * from pg_stat_replication where application_name = '$slot'" -x) \
                    <(psql_upstream "select * from pg_replication_slots where slot_name = '$slot'" -x)

                tail -n 5 "$log"/*.log "$standbylog"

                exit $((status1 + status2))
                ;;

            start)
                check_not_retired
                $0 wal_archive start || true
                $0 standby start
                ;;

            stop)
                $0 wal_archive stop || true
                $0 standby stop
                ;;

            checkversions)
                status=0
                current_upstream_version=$(get_upstream_version)
                if [[ "$current_upstream_version" != "$upstream_version" ]]; then
                    log "Upstream is version $current_upstream_version instead of expected $upstream_version."
                    log "If upstream has been upgraded you have to create a new container to archive it, and you should retire this one."
                    status=1
                else
                    log "Upstream version $upstream_version matches expectation."
                fi
                check_pg_apps $upstream_version || status=1
                exit $status
                ;;

            retire)
                check_not_retired
                if [[ "$1" = '--force' ]]; then
                    set +e
                fi
                container_retire
                ;;

            resync)
                check_retired
                container_resync
                ;;

            upstream)
                psql "$upstream" "$@"
                ;;

            *)
                fail "unknown container command"
                ;;
        esac
        ;;

    *)
        configure
        ;;&

    wal_archive)
        subcmd=$1
        shift || true

        curpid=`cat $walpid 2>/dev/null` || true
        running() {
            [[ -n "$curpid" && -d "/proc/$curpid" ]] &&
                grep "pg_receivexlog.*--slot=$slot" "/proc/$curpid/cmdline" >/dev/null
        }

        case "$subcmd" in
            status)
                running \
                    && log "wal_archive is running (pid=$curpid)" \
                    || (log "wal_archive is not running" ; exit 1)
                ;;

            start)
                check_not_retired
                running && fail "wal_archive is already running (pid=$curpid)"

                log "starting wal_archive process $slot"
                PGAPPNAME="$slot" \
                    pg_receivexlog -D "$wal" --slot="$slot" --verbose --no-password \
                    -d "$upstream_repl" >>"$log/wal_archive.log" 2>&1 &
                echo $! > "$walpid"
                ;;

            stop)
                running || fail "wal_archive is not running"

                log "stopping wal_archive (pid=$curpid)"
                kill "$curpid"
                sleep 0.5
                while [[ -d /proc/$curpid ]]; do
                    echo -n "."
                    sleep 1
                done
                echo ""
                ;;

            log)
                show_log "$1" "$wallog"
                ;;

            list)
                ls -l $wal
                ;;

            du)
                awk_wal_size='
                    $8 ~ /........................(.gz)?$/ { count[$7]++ ; size[$7] += $1 }
                    END {
                        printf "Date\t\tNumber\tMB\tCompression\n"
                        asorti(count, sorted)
                        n=length(sorted)
                        for (i=1; i<=n; ++i) {
                            d=sorted[i]
                            c=count[d]
                            s=size[d]/1024
                            printf "%s\t%d\t%d\t%3.0f%%\n", d, c, s, 100-s/c/16*100
                        }
                    }'
                echo "WAL segments in $wal:"
                ls --sort=none --size --kibibytes --time-style="+%Y-%m-%d" -l "$wal" \
                    | gawk "$awk_wal_size"
                du -sh $wal
                ;;

            *)
                fail "unknown wal_archive command"
                ;;
        esac
        ;;

    standby)
        subcmd=$1
        shift || true

        case "$subcmd" in
            log)
                show_log "$1" "$standbylog"
                ;;

            start|stop|status|reload|restart)
                check_not_retired
                pg_ctl_cmd "$standby" "$subcmd" $@
                status=$?
                [[ "$subcmd" = *start ]] && sleep 2
                exit $status
                ;;

            *)
                fail "unknown standby command"
                ;;
        esac
        ;;

    snapshot)
        subcmd=$1
        shift || true

        case "$subcmd" in
            list)
                cd "$snapshots"
                if [[ -n "$@" ]]; then
                    ls -1d $@
                else
                    ls -1
                fi
                ;;

            create)
                check_not_retired
                date=$(snapshot_date)
                [[ -e "$snapshots/$date" ]] && log "The snapshot $date already exists." && exit 0

                if [[ "$1" = "--force" ]]; then
                    snapshot_create "$date"
                else
                    pg_ctl_status "$standby" ||
                        fail "No snapshot was created because the standby process is not running, start it or use --force."
                    snapshot_check_cleanup_position $snapshot_max_restartpoint_minutes ||
                        fail "No snapshot was created because the last restartpoint is more than $snapshot_max_restartpoint_minutes minutes old. Check your standby process."

                    # We could snapshot while the standby is running, but this seems to kill
                    # PG with ENOSPC (no matter the real free space) too often :-(
                    # Note also we must not capture possibly flock'ed file descriptors if
                    # called via "cron expire-and-create-snapshot".
                    # At least this saves some time (crash recovery) at clone start.
                    pg_ctl_cmd "$standby" stop >/dev/null 2>/dev/null
                    snapshot_create
                    pg_ctl_cmd "$standby" start >/dev/null 2>/dev/null
                fi
                ;;

            expire)
                expire_date="${EXPIRE_DATE:-$expire_date}"
                [[ -n "$expire_date" ]] || fail 'No $expire_date or $EXPIRE_DATE set.'
                [[ "$1" = "--show" ]] && enable_dry_run
                snapshot_expire
                ;;

            thin)
                thin_daily_date="${THIN_DAILY_DATE:-$thin_daily_date}"
                [[ -n "$thin_daily_date" ]] || fail 'No $thin_daily_date or $THIN_DAILY_DATE set.'
                [[ "$1" = "--show" ]] && enable_dry_run
                snapshot_thin_daily
                ;;

            delete)
                fs_delete_subvolume "$snapshots/$1"
                ;;

            *)
                fail "unknown snapshot command"
                ;;
        esac
        ;;

    clone)
        subcmd=$1
        shift || true

        case "$subcmd" in
            list)
                if [[ "$1" = "--status" ]]; then
                    set +e
                    for c in $(cd "$clones" && [[ -n "$2" ]] && ls -d $2 || ls) ; do
                        port=$(grep '^port =' "$clones/$c"/postgresql.conf | tail -n1 | cut -d" " -f3)
                        echo "*** $c (port=$port) ***"
                        $0 clone status $c
                    done
                else
                    cd "$clones"
                    [[ -n "$1" ]] && ls -d $1 || ls
                fi
                ;;

            create)
                clone_create "$@"
                ;;

            *)
                clone="$clones/$1"
                [[ "$1" = "--all" ]] && all=1
                [[ -n "$1" ]] || fail "clone name required"
                [[ -d "$clone" ]] || [[ "$subcmd" = "stop" && -n "$all" ]] \
                    || fail "clone $1 does not exist"
                shift
                ;;&

            duplicate)
                clone_duplicate "$@"
                ;;

            delete)
                # Note this fails on purpose if the instance is running.
                fs_delete_subvolume $btrfs_commit "$clone"
                ;;

            log)
                show_log "$1" "$clone/pg_log/postgresql-$(date +'%a').csv"
                ;;

            psql)
                port=$(grep '^port =' "$clone"/postgresql.conf | tail -n1 | cut -d" " -f3)
                psql -p $port "$@"
                ;;

            stop)
                if [[ -n "$all" ]]; then
                    for c in "$clones"/* ; do
                        ! pg_ctl_status "$c" || pg_ctl_cmd "$c" stop $@
                    done
                else
                    pg_ctl_cmd "$clone" stop $@
                fi
                ;;

            start|status|reload|restart)
                pg_ctl_cmd "$clone" "$subcmd" $@
                status=$?
                [[ "$subcmd" = *start ]] && sleep 2
                exit $status
                ;;

            *)
                fail "unknown clone command"
                ;;
        esac
        ;;

    cron)
        subcmd=$1
        shift || true

        case "$subcmd" in
            compress-wal-archive)
                (
                    flock --nonblock 1 || fail "Another compress-wal-archive is still running."
                    if [[ -f $standby_cleanup_position ]] ; then
                        cutoff=$(<$standby_cleanup_position)
                        log "compress-wal-archive up to $cutoff"
                        pg_archivecleanup -n "$wal" "$cutoff" | xargs -r -n 16 -P "$compress_threads" gzip -f
                    else
                        log "No $standby_cleanup_position."
                    fi
                ) >>"$cron_wallog" 2>&1
                ;;

            expire-and-create-snapshot)
                (
                    flock --nonblock 1 || fail "Another expire-and-create-snapshot is still running."
                    log "*** expire-and-create-snapshot ***"
                    $0 snapshot expire || true
                    $0 snapshot thin || true
                    [[ -n "$retired" ]] || $0 snapshot create
                ) >>"$cron_snapshotlog" 2>&1
                ;;

            maintenance|defrag-btrfs)
                (
                    [[ -z "$retired" ]] || fail "Skipping maintenance, container is retired."
                    flock --nonblock 1 || fail "Another maintenance job is still running."
                    log "Maintenance starting."
                    fs_maintenance "$container"
                ) >>"$cron_maintenancelog" 2>&1
                ;;

            *)
                fail "unknown cron command"
                ;;
        esac
        ;;

    *)
        fail "unknown command, try 'help'"
        ;;
esac
